{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tic Tac Toe game\n",
    "# Using Reinforcement Learning and Epsilon-Greedy algoirthm\n",
    "# Inspired by LazyProgrammer & Udemy's online course\n",
    "# By: Mohamad Nasr-Azadani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LENGTH = 3\n",
    "class Environment():\n",
    "    def __init__(self):\n",
    "        self.board = np.zeros((LENGTH,LENGTH), dtype=int)\n",
    "        self.X = -1\n",
    "        self.O = +1\n",
    "        self.Empty = 0\n",
    "        self._signs = {1: 'O', -1: 'X', 0: ' '}\n",
    "        self.winner = None\n",
    "        self.ended = False\n",
    "        self.num_states = 3**(LENGTH*LENGTH)\n",
    "    \n",
    "    def is_empty(self, i, j):\n",
    "        return self.board[i,j] == self.Empty\n",
    "    \n",
    "    def game_over(self, force_check=False):\n",
    "        def _win_by_row(which_player):\n",
    "            \"\"\"\n",
    "            Check if player won by completing a row\n",
    "            \"\"\"\n",
    "            win_sum_value = which_player*LENGTH\n",
    "            for i in range(LENGTH):\n",
    "                if self.board[i].sum() == win_sum_value:\n",
    "                    return True\n",
    "            return False\n",
    "        \n",
    "        def _win_by_column(which_player):\n",
    "            \"\"\"\n",
    "            Check if player won by completing a column\n",
    "            \"\"\"\n",
    "            win_sum_value = which_player*LENGTH\n",
    "            for j in range(LENGTH):\n",
    "                if self.board[:, j].sum() == win_sum_value:\n",
    "                    return True\n",
    "            return False\n",
    "        \n",
    "        def _win_by_diagonal(which_player):\n",
    "            \"\"\"\n",
    "            Check if player won by completing a diagonal\n",
    "            \"\"\"\n",
    "            win_sum_value = which_player*LENGTH\n",
    "            sum_diag1 = 0\n",
    "            sum_diag2 = 0\n",
    "            for i in range(LENGTH):\n",
    "                # sum of main diagonal\n",
    "                sum_diag1 += self.board[i,i] # main diagonal\n",
    "                # sum of the other diagonal (top-right to botto left)\n",
    "                sum_diag2 += self.board[i,LENGTH-i-1]\n",
    "            if sum_diag1 == win_sum_value or sum_diag2 == win_sum_value:\n",
    "                return True\n",
    "            \n",
    "            return False\n",
    "        \n",
    "        def _is_board_full():\n",
    "            \"\"\"\n",
    "            Check if (LENGTH*LENGTH) board is full.\n",
    "            \"\"\"\n",
    "            if np.all( (self.board == self.Empty) == False):\n",
    "                return True\n",
    "            return False\n",
    "\n",
    "        # If game is already ended and we are not forcing for another check, \n",
    "        # then just return the ended flag\n",
    "        if not force_check and self.ended:\n",
    "            return self.ended\n",
    "        \n",
    "        for p in (self.X,self.O):\n",
    "            if _win_by_row(which_player=p) or _win_by_column(which_player=p) or _win_by_diagonal(which_player=p):\n",
    "                self.winner = p\n",
    "                self.ended = True\n",
    "                return True\n",
    "            \n",
    "        # If we made it here, then there is definitely no winner.\n",
    "        self.winner = None\n",
    "\n",
    "        # If board is full, then game over, else, continue the game.\n",
    "        self.ended = _is_board_full()\n",
    "        return self.ended\n",
    "    \n",
    "    def is_tie(self):\n",
    "        \"\"\"\n",
    "        Returns if the game is tied (ended and no winner)\n",
    "        \"\"\"\n",
    "        return self.ended and self.winner is None\n",
    "    \n",
    "    def show_board(self):\n",
    "        def _get_char(i,j):\n",
    "            return self._signs[self.board[i,j]]\n",
    "            \n",
    "        for i in range(LENGTH):\n",
    "            print('-'*(4*LENGTH+1))\n",
    "            s = ['|']\n",
    "            for j in range(LENGTH):\n",
    "                char = _get_char(i,j)\n",
    "                s.append(char)\n",
    "                s.append('|')\n",
    "            print(' '.join(s))\n",
    "        print('-'*(4*LENGTH+1))\n",
    "    \n",
    "    def get_state(self):\n",
    "    # returns the current state, represented as an int\n",
    "    # from 0...|S|-1, where S = set of all possible states\n",
    "    # |S| = 3^(BOARD SIZE), since each cell can have 3 possible values - empty, x, o\n",
    "    # some states are not possible based on rule's game, e.g. all cells are x, \n",
    "    # but we ignore that detail. \n",
    "    # This is like finding the integer represented by a base-3 number\n",
    "        def _get_val(i,j):\n",
    "            \"\"\"\n",
    "            Assign a unique value for each cell-state. \n",
    "            X = 1, O = 2, Empty = 0\n",
    "            \"\"\"\n",
    "            if self.board[i,j] == self.X:\n",
    "                return 1\n",
    "            if self.board[i,j] == self.O:\n",
    "                return 2\n",
    "            return 0\n",
    "        # Go through the board, and create a single number from the values stored.\n",
    "        # Assign unique values for each case. \n",
    "        k, h = 0, 0\n",
    "        for i in range(LENGTH):\n",
    "            for j in range(LENGTH):\n",
    "                v = _get_val(i,j)\n",
    "                h += (3**k) * v\n",
    "                k += 1\n",
    "        return h\n",
    "    \n",
    "    def get_winner(self):\n",
    "        return self.winner\n",
    "    \n",
    "    def set_cell(self, idx_tuple, which_player):\n",
    "        i = idx_tuple[0]\n",
    "        j = idx_tuple[1]\n",
    "        if not self.is_empty(i,j):\n",
    "            raise ValueError('Error. Cannot place {} in cell at (i,j)=({},{}).\\\n",
    "            Cell already occupied.'.format(which_player, i, j))\n",
    "        else:\n",
    "            self.board[i,j] = which_player\n",
    "            \n",
    "    def reset_cell(self, idx_tuple):\n",
    "        i = idx_tuple[0]\n",
    "        j = idx_tuple[1]\n",
    "        self.board[i,j] = self.Empty\n",
    "\n",
    "    def reward(self, which_player):\n",
    "        # If game is still on, just pass 0 as reward\n",
    "        if not self.game_over():\n",
    "            return 0\n",
    "        # Game is ended. Check if winner is which_player, give a positive reward.\n",
    "        # If not, a 0 reward\n",
    "        if self.get_winner() == which_player:\n",
    "            return 1\n",
    "        # Question: What happens to draw or if other player wins? \n",
    "        # Why no negative reward?\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, which_player=None, eps=0.1, alpha=0.5):\n",
    "        # epsilon: in Epsilon-Greedy algorithm.\n",
    "        # Choose a small number. The probability of choosing a random action.\n",
    "        self._eps = eps\n",
    "        # learning rate\n",
    "        self._alpha = alpha\n",
    "        # array tracking state histroy of the game\n",
    "        self.state_history = []\n",
    "        if not which_player:\n",
    "            raise ValueError('which_player cannot be None. Set either \"X\" or \"O\" for different players')\n",
    "        else:\n",
    "            self._set_player(which_player)\n",
    "    \n",
    "    def setVs(self, V=[]):\n",
    "        self._V = V\n",
    "    \n",
    "    def getV_for_state(self, state):\n",
    "        return self._V[state]\n",
    "\n",
    "    def _set_player(self, p):\n",
    "        if p in ['X', 'x']:\n",
    "            self._player = -1\n",
    "        elif p in ['O', 'o']:\n",
    "            self._player = +1\n",
    "        else:\n",
    "            raise ValueError('Error. Unexpected player symbol {}. Use \"X\" or \"O\" '.format(p))\n",
    "        \n",
    "    def get_player(self):\n",
    "        return self._player\n",
    "    \n",
    "    def get_player_symbol(self):\n",
    "        return 'X' if self._player == -1 else 'O'\n",
    "\n",
    "    def reset_history(self):\n",
    "        self.state_history = []\n",
    "\n",
    "    def take_action(self, env, show_greedy_values=False):\n",
    "        def _explore(env):\n",
    "            \"\"\"\n",
    "            Explore step. Pick an empty cell on the board randomly.\n",
    "            \"\"\"\n",
    "            def __possible_cells():\n",
    "                empty_cells = []\n",
    "                for i in range(LENGTH):\n",
    "                    for j in range(LENGTH):\n",
    "                        if env.is_empty(i,j):\n",
    "                            empty_cells.append((i,j))\n",
    "                return empty_cells\n",
    "\n",
    "            # First, collect all possible cells (non-empty) on the board\n",
    "            empty_cells = __possible_cells()\n",
    "            # Now pick one randomly\n",
    "            idx = np.random.choice(len(empty_cells))\n",
    "            # Next, store the randomly chosen empty cell index (i,j) on the board\n",
    "            return empty_cells[idx]\n",
    "        \n",
    "        def _exploit(env):\n",
    "            \"\"\"\n",
    "            Exploit step. Go through all possible actions (next empty cell),\n",
    "            with the possible next move, find the state and value for new state. \n",
    "            Return the best next cell with the most value.\n",
    "            \"\"\"\n",
    "            def __print_values():\n",
    "                print(\"Taking a greedy action:\")\n",
    "                for i in range(LENGTH):\n",
    "                    print('-'*(7*LENGTH+1))\n",
    "                    s = ['|']\n",
    "                    for j in range(LENGTH):\n",
    "                        if env.is_empty(i,j):\n",
    "                            v = format(pos2value[(i,j)], '.2f')\n",
    "                            s.append(v)\n",
    "                        elif env.board[i,j] == env.X:\n",
    "                            s.append('  X ')\n",
    "                        elif env.board[i,j] == env.O:\n",
    "                            s.append('  O ')\n",
    "                        s.append('|')\n",
    "                    print(' '.join(s))\n",
    "                print('-'*(7*LENGTH+1))\n",
    "                \n",
    "            V_best = -10\n",
    "            next_cell = None\n",
    "            # for showing values only\n",
    "            pos2value = {}\n",
    "            for i in range(LENGTH):\n",
    "                for j in range(LENGTH):\n",
    "                    if env.is_empty(i,j):\n",
    "                        env.set_cell((i,j), which_player=self.get_player())\n",
    "                        Poss_state = env.get_state()\n",
    "                        V_poss = self.getV_for_state(Poss_state)\n",
    "                        pos2value[(i,j)] = V_poss\n",
    "                        if V_poss > V_best:\n",
    "                            V_best = V_poss\n",
    "                            State_best = Poss_state\n",
    "                            next_cell = (i,j)\n",
    "                        # now reset the cell again\n",
    "                        env.reset_cell((i,j))\n",
    "            if show_greedy_values:\n",
    "                __print_values()\n",
    "                    \n",
    "            return next_cell\n",
    "        \n",
    "        # Choose an action using epsilon-greedy algorithm\n",
    "        r = np.random.rand()\n",
    "        # cell index: (i,j)\n",
    "        next_cell = None\n",
    "        if r < self._eps:\n",
    "            next_cell = _explore(env)\n",
    "        else:\n",
    "            next_cell = _exploit(env)\n",
    "            \n",
    "        which_player = self.get_player()\n",
    "        env.set_cell(next_cell, which_player)\n",
    "    \n",
    "    def update_state_history(self, st):\n",
    "        \"\"\"\n",
    "        Append the latest state to state_history list\n",
    "        \"\"\"\n",
    "        self.state_history.append(st)\n",
    "    \n",
    "    def update(self, env):\n",
    "        # we want to BACKTRACK over the states, so that:\n",
    "        # V(prev_state) = V(prev_state) + alpha*(V(next_state) - V(prev_state))\n",
    "        # where V(next_state) = reward if it's the most current state\n",
    "        #\n",
    "        # NOTE: we ONLY do this at the end of an episode (game ended)\n",
    "        # (not so for all the algorithms we will study)\n",
    "\n",
    "        # First, get the reward at this (final) state.\n",
    "        reward = env.reward(which_player=self.get_player())\n",
    "        target = reward\n",
    "        # Now, go through all the preview states (from first move to last move)\n",
    "        # update their values using the final 'reward'.\n",
    "        for prev_state in reversed(self.state_history):\n",
    "            V_prev = self.getV_for_state(prev_state)\n",
    "            value = V_prev + self._alpha*(target - V_prev)\n",
    "            self._V[prev_state] = value\n",
    "            target = value\n",
    "        # Since we have reached to the end of the game, we reset state history. \n",
    "        self.reset_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Human:\n",
    "    def __init__(self, which_player=None):\n",
    "        if not which_player:\n",
    "            raise ValueError('which_player cannot be None. Set either \"X\" or \"O\" for different players')\n",
    "        else:\n",
    "            self._set_player(which_player)\n",
    "\n",
    "    def _set_player(self, p):\n",
    "        if p in ['X', 'x']:\n",
    "            self._player = -1\n",
    "        elif p in ['O', 'o']:\n",
    "            self._player = 1\n",
    "        else:\n",
    "            raise ValueError('Error. Unexpected player symbol {}. Use \"X\" or \"O\" '.format(p))\n",
    "        \n",
    "    def get_player(self):\n",
    "        return self._player\n",
    "\n",
    "    def get_player_symbol(self):\n",
    "        return 'X' if self._player == -1 else 'O'\n",
    "    \n",
    "    def take_action(self, env, show_greedy_values=False):\n",
    "        while True:\n",
    "            # break if we make a legal move\n",
    "            move = input(\"Enter coordinates i,j for your next move (i,j=0..2): \")\n",
    "            if sys.version_info[0] < 3:\n",
    "                i, j = move[0], move[1]\n",
    "            else:\n",
    "                i, j = move.split(',')\n",
    "            i = int(i)\n",
    "            j = int(j)\n",
    "            if env.is_empty(i, j):\n",
    "                env.board[i,j] = self.get_player()\n",
    "                break\n",
    "            else:\n",
    "                print(\"Try again. Cell is already taken.\")\n",
    "\n",
    "    def update(self, env):\n",
    "        pass\n",
    "\n",
    "    def update_state_history(self, st):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_game(p1, p2, env, show_board=False, show_which_player=None, show_greedy_values=False):\n",
    "    \"\"\"\n",
    "    Play game. We assume p1 and p2 are of types Agent().\n",
    "    For training phase, p1 and p2 should be Agent(). \n",
    "    For testing, p2 can be of class type Human(). \n",
    "    \"\"\"\n",
    "    def _update_current_player(p1, p2, current_player):\n",
    "        \"\"\"\n",
    "        Swap player's turn\n",
    "        \"\"\"\n",
    "        return p2 if current_player == p1 else p1\n",
    "        \n",
    "    current_player = None\n",
    "    while not env.game_over():\n",
    "        # Alternate between p1 and p2. \n",
    "        # p1 starts first\n",
    "        current_player = _update_current_player(p1, p2, current_player)\n",
    "        \n",
    "        # draw the board if needed\n",
    "        if show_board: \n",
    "            if show_which_player==1 and current_player == p1:\n",
    "                env.show_board()\n",
    "            if show_which_player==2 and current_player == p2:\n",
    "                env.show_board()\n",
    "            \n",
    "        # current player makes a new move\n",
    "        current_player.take_action(env, show_greedy_values=show_greedy_values)\n",
    "        \n",
    "        # get current state\n",
    "        state = env.get_state()\n",
    "        # allow player 1 and 2 to update their state history accordingly\n",
    "        p1.update_state_history(state)\n",
    "        p2.update_state_history(state)\n",
    "    \n",
    "    # game ended\n",
    "    if show_board:\n",
    "        print('*'*25)\n",
    "        print('Game ended.')\n",
    "        env.show_board()\n",
    "        \n",
    "    p1.update(env)\n",
    "    p2.update(env)\n",
    "    \n",
    "    return env.ended,env.winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_states_and_winner(env, i=0, j=0):\n",
    "    # recursive function that will return all\n",
    "    # possible states (as ints) and who the corresponding winner is for those states (if any)\n",
    "    # (i, j) refers to the next cell on the board to permute (we need to try -1, 0, 1)\n",
    "    # impossible games are ignored, i.e. 3x's and 3o's in a row simultaneously\n",
    "    # since that will never happen in a real game\n",
    "    results = []\n",
    "    \n",
    "    for v in (env.X, env.O, env.Empty):\n",
    "        env.board[i,j] = v\n",
    "        if j == LENGTH-1:\n",
    "        # j goes back to 0, increase i, unless i = LENGTH-1, then we are done\n",
    "            if i == LENGTH-1:\n",
    "                state = env.get_state()\n",
    "                ended = env.game_over(force_check=True)\n",
    "                winner = env.get_winner()\n",
    "                results.append((state,winner,ended))\n",
    "            else: # i\n",
    "                # increment i\n",
    "                results += get_states_and_winner(env, i+1, 0)\n",
    "        else: # j\n",
    "            # increment j\n",
    "            results += get_states_and_winner(env, i, j+1)\n",
    "            \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_V(env, state_winner_triples, which_player=None):\n",
    "    \"\"\"\n",
    "    Initialize Value functions from triples (state,winner,ended).\n",
    "    State is a value representing the board.\n",
    "  # initialize state values as follows\n",
    "  # if x wins, V(s) = 1\n",
    "  # if x loses or draw, V(s) = 0\n",
    "  # otherwise, V(s) = 0.5\n",
    "    \"\"\"\n",
    "    V = np.zeros(env.num_states)\n",
    "    for state, winner, ended in state_winner_triples:\n",
    "        if ended:\n",
    "            v = 1 if winner == which_player else 0\n",
    "        else:\n",
    "            v = 0.5\n",
    "        V[state] = v\n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_players(player1, player2, env, training_count=5000):\n",
    "    # First, get triples of all possible states of the game:\n",
    "    # (state,ended,winner)\n",
    "    state_winner_triples = get_states_and_winner(env)\n",
    "\n",
    "    # Now initialize Value function for player 1\n",
    "    V1 = initialize_V(env, state_winner_triples, which_player=player1.get_player())\n",
    "    player1.setVs(V1)\n",
    "\n",
    "    # Initialize Value function for player 2\n",
    "    V2 = initialize_V(env, state_winner_triples, which_player=player2.get_player())\n",
    "    player2.setVs(V2)\n",
    "\n",
    "    for t in range(training_count):\n",
    "        ended, winner = play_game(player1, player2, Environment())\n",
    "        if t % 500 == 0:\n",
    "            print('Training {} games.'.format(t))\n",
    "    print('Trainng completed after {} practice rounds.'.format(training_count))\n",
    "\n",
    "    return player1, player2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 0 games.\n",
      "Training 500 games.\n",
      "Trainng completed after 1000 practice rounds.\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "p1 = Agent(which_player='X')\n",
    "p2 = Agent(which_player='O')\n",
    "\n",
    "env = Environment()\n",
    "p1, p2 = train_players(p1, p2, env, training_count=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game started ***************************.\n",
      "-------------\n",
      "|   |   |   |\n",
      "-------------\n",
      "|   |   |   |\n",
      "-------------\n",
      "|   |   |   |\n",
      "-------------\n",
      "Enter coordinates i,j for your next move (i,j=0..2): 1,1\n",
      "Taking a greedy action:\n",
      "----------------------\n",
      "| 0.03 | 0.03 | 0.04 |\n",
      "----------------------\n",
      "| 0.04 |   X  | 0.01 |\n",
      "----------------------\n",
      "| 0.03 | 0.04 | 0.03 |\n",
      "----------------------\n",
      "-------------\n",
      "|   |   | O |\n",
      "-------------\n",
      "|   | X |   |\n",
      "-------------\n",
      "|   |   |   |\n",
      "-------------\n",
      "Enter coordinates i,j for your next move (i,j=0..2): 0,0\n",
      "Taking a greedy action:\n",
      "----------------------\n",
      "|   X  | 0.25 |   O  |\n",
      "----------------------\n",
      "| 0.02 |   X  | 0.25 |\n",
      "----------------------\n",
      "| 0.25 | 0.25 | 0.53 |\n",
      "----------------------\n",
      "-------------\n",
      "| X |   | O |\n",
      "-------------\n",
      "|   | X |   |\n",
      "-------------\n",
      "|   |   | O |\n",
      "-------------\n",
      "Enter coordinates i,j for your next move (i,j=0..2): 1,2\n",
      "Taking a greedy action:\n",
      "----------------------\n",
      "|   X  | 0.25 |   O  |\n",
      "----------------------\n",
      "| 0.23 |   X  |   X  |\n",
      "----------------------\n",
      "| 0.50 | 0.50 |   O  |\n",
      "----------------------\n",
      "-------------\n",
      "| X |   | O |\n",
      "-------------\n",
      "|   | X | X |\n",
      "-------------\n",
      "| O |   | O |\n",
      "-------------\n",
      "Enter coordinates i,j for your next move (i,j=0..2): 2,1\n",
      "Taking a greedy action:\n",
      "----------------------\n",
      "|   X  | 0.25 |   O  |\n",
      "----------------------\n",
      "| 0.50 |   X  |   X  |\n",
      "----------------------\n",
      "|   O  |   X  |   O  |\n",
      "----------------------\n",
      "-------------\n",
      "| X |   | O |\n",
      "-------------\n",
      "| O | X | X |\n",
      "-------------\n",
      "| O | X | O |\n",
      "-------------\n",
      "Enter coordinates i,j for your next move (i,j=0..2): 0,1\n",
      "*************************\n",
      "Game ended.\n",
      "-------------\n",
      "| X | X | O |\n",
      "-------------\n",
      "| O | X | X |\n",
      "-------------\n",
      "| O | X | O |\n",
      "-------------\n",
      "Game over ******************************.\n",
      "Player \"X\" won. Play again? [Y/n]\n",
      "y\n",
      "Game started ***************************.\n",
      "-------------\n",
      "|   |   |   |\n",
      "-------------\n",
      "|   |   |   |\n",
      "-------------\n",
      "|   |   |   |\n",
      "-------------\n",
      "Enter coordinates i,j for your next move (i,j=0..2): 2,2\n",
      "Taking a greedy action:\n",
      "----------------------\n",
      "| 0.44 | 0.44 | 0.55 |\n",
      "----------------------\n",
      "| 0.50 | 0.50 | 0.50 |\n",
      "----------------------\n",
      "| 0.50 | 0.50 |   X  |\n",
      "----------------------\n",
      "-------------\n",
      "|   |   | O |\n",
      "-------------\n",
      "|   |   |   |\n",
      "-------------\n",
      "|   |   | X |\n",
      "-------------\n",
      "Enter coordinates i,j for your next move (i,j=0..2): 0,0\n",
      "Taking a greedy action:\n",
      "----------------------\n",
      "|   X  | 0.25 |   O  |\n",
      "----------------------\n",
      "| 0.50 | 0.62 | 0.50 |\n",
      "----------------------\n",
      "| 0.25 | 0.50 |   X  |\n",
      "----------------------\n",
      "-------------\n",
      "| X |   | O |\n",
      "-------------\n",
      "|   | O |   |\n",
      "-------------\n",
      "|   |   | X |\n",
      "-------------\n",
      "Enter coordinates i,j for your next move (i,j=0..2): 2,0\n",
      "Taking a greedy action:\n",
      "----------------------\n",
      "|   X  | 0.50 |   O  |\n",
      "----------------------\n",
      "| 0.50 |   O  | 0.50 |\n",
      "----------------------\n",
      "|   X  | 0.50 |   X  |\n",
      "----------------------\n",
      "-------------\n",
      "| X | O | O |\n",
      "-------------\n",
      "|   | O |   |\n",
      "-------------\n",
      "| X |   | X |\n",
      "-------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/python-venvs/opencv_python3/lib/python3.6/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python-venvs/opencv_python3/lib/python3.6/site-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python-venvs/opencv_python3/lib/python3.6/site-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    465\u001b[0m         \"\"\"\n\u001b[0;32m--> 466\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/python-venvs/opencv_python3/lib/python3.6/site-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-55a8316cee10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Game started ***************************.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mHUMAN_FIRST\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mended\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwinner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplay_game\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhuman\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEnvironment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_board\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_which_player\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_greedy_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mended\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwinner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplay_game\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhuman\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEnvironment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_board\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_which_player\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_greedy_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-73749fda13a8>\u001b[0m in \u001b[0;36mplay_game\u001b[0;34m(p1, p2, env, show_board, show_which_player, show_greedy_values)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# current player makes a new move\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mcurrent_player\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_greedy_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_greedy_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# get current state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-6fa4e78b7fb8>\u001b[0m in \u001b[0;36mtake_action\u001b[0;34m(self, env, show_greedy_values)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;31m# break if we make a legal move\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mmove\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter coordinates i,j for your next move (i,j=0..2): \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmove\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmove\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python-venvs/opencv_python3/lib/python3.6/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python-venvs/opencv_python3/lib/python3.6/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "HUMAN_FIRST = False\n",
    "if HUMAN_FIRST:\n",
    "    human = Human(which_player='X')\n",
    "else:\n",
    "    human = Human(which_player='O')\n",
    "\n",
    "while True:\n",
    "    print(\"Game started ***************************.\")\n",
    "    if HUMAN_FIRST:\n",
    "        ended, winner = play_game(human, p2, Environment(), show_board=True, show_which_player=1, show_greedy_values=True)\n",
    "    else:\n",
    "        ended, winner = play_game(p1, human, Environment(), show_board=True, show_which_player=2, show_greedy_values=True)\n",
    "    print(\"Game over ******************************.\")\n",
    "    if not winner:\n",
    "        print(\"Draw. Play again? [Y/n]\")\n",
    "    else:\n",
    "        symb = 'X' if winner == -1 else 'O'\n",
    "        print('Player \"{}\" won. Play again? [Y/n]'.format(symb))\n",
    "    answer = input()\n",
    "    if answer and answer.lower()[0] == 'n':\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
